# -*- coding: utf-8 -*-
"""Advertising.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EmdmULRwbePPZofOdk6rRFP2Oa8eOz9o
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
import statsmodels.api as sm
import statsmodels.formula.api as smf
from scipy import stats
plt.style.use('seaborn')

import pandas as pd
import io
df = pd.read_csv(io.BytesIO(uploaded['advertising.csv']))
df

X = df[['TV', 'Radio', 'Newspaper']]
y = df['Sales']

X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size = 0.2, random_state = 0, shuffle = True)

X_train = sm.add_constant(X_train, prepend=True)
modelo = sm.OLS(endog=y_train, exog=X_train,)
modelo = modelo.fit()
print(modelo.summary())

"""El p-valor de la variable periodico es mayor al 5%, por lo tanto se acepta la hipotesis nula que afirma que esa variable no aporta al modelo, y por lo tanto la podemos retirar. El  2=0.913  es alto, lo que implica que el modelo se ajusta muy bien a los datos, explicando hasta el 91.3% la variabilidad observada en las ventas. """

#Se procede a elimiar la variable periodico.
X_train = X_train.drop(columns = 'Newspaper')
X_test  = X_test.drop(columns = 'Newspaper')

X_train

X_train = sm.add_constant(X_train, prepend=True)
modelo  = sm.OLS(endog=y_train, exog=X_train,)
modelo  = modelo.fit()
print(modelo.summary())

X_test = sm.add_constant(X_test, prepend=True)
predicciones = modelo.predict(exog = X_test)
rmse = mean_squared_error(y_true  = y_test, y_pred = predicciones, squared = False)
print("")
print(f"El error (rmse) de test es: {rmse}")

"""#Conclusi贸n:
El modelo de regresi贸n lineal m煤ltiple:

$$ventas = 4.7183 + 0.0536\;TV + 0.1099\;Radio$$
 
este modelo es capaz de explicar que el 91.1% de la varianza observada en las ventas (R-squared: 0.913, Adj. R-squared: 0.912) es mejor de lo esperado por azar. El test  F  es significativo (p-value: 5.54e-84). Los test estad铆sticos para cada variable confirman que tv y radio est谩n relacionadas con la cantidad de ventas y contribuyen al modelo.

El error (rmse) de test es de 2.1158. Las predicciones del modelo final se alejan en promedio 2.1158 unidades del valor real.

#La empresa deber铆a destinar su mayor cantidad de ingresos en la publicidad trasmitida por la Radio.
"""

intervalos_ci = modelo.conf_int(alpha=0.05)
intervalos_ci.columns = ['2.5%', '97.5%']
intervalos_ci['valores'] = [modelo.params[0], modelo.params[1], modelo.params[2]]
intervalos_ci

prediccion_train = modelo.predict(exog = X_train)
residuos_train   = prediccion_train - y_train

fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(9, 8))

axes[0, 0].scatter(y_train, prediccion_train, edgecolors=(0, 0, 0), alpha = 0.4)
axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()],
                'k--', color = 'black', lw=2)
axes[0, 0].set_title('Valor predicho vs valor real', fontsize = 10, fontweight = "bold")
axes[0, 0].set_xlabel('Real')
axes[0, 0].set_ylabel('Predicci贸n')
axes[0, 0].tick_params(labelsize = 7)

axes[0, 1].scatter(list(range(len(y_train))), residuos_train, edgecolors=(0, 0, 0), alpha = 0.4)
axes[0, 1].axhline(y = 0, linestyle = '--', color = 'black', lw=2)
axes[0, 1].set_title('Residuos del modelo', fontsize = 10, fontweight = "bold")
axes[0, 1].set_xlabel('id')
axes[0, 1].set_ylabel('Residuo')
axes[0, 1].tick_params(labelsize = 7)

sns.distplot(residuos_train, kde = True, color = "firebrick", ax= axes[1, 0], hist_kws={'linewidth': 1})
axes[1, 0].set_ylabel('Density')
axes[1, 0].set_title('Distribuci贸n residuos del modelo', fontsize = 10,
                     fontweight = "bold")
axes[1, 0].set_xlabel("Residuo")
axes[1, 0].tick_params(labelsize = 7)


sm.qqplot(
    residuos_train,
    fit   = True,
    line  = 'q',
    ax    = axes[1, 1], 
    color = 'firebrick',
    alpha = 0.4,
    lw    = 2
)
axes[1, 1].set_title('Q-Q residuos del modelo', fontsize = 10, fontweight = "bold")
axes[1, 1].tick_params(labelsize = 7)

axes[2, 0].scatter(prediccion_train, residuos_train,
                   edgecolors=(0, 0, 0), alpha = 0.4)
axes[2, 0].axhline(y = 0, linestyle = '--', color = 'black', lw=2)
axes[2, 0].set_title('Residuos del modelo vs predicci贸n', fontsize = 10, fontweight = "bold")
axes[2, 0].set_xlabel('Predicci贸n')
axes[2, 0].set_ylabel('Residuo')
axes[2, 0].tick_params(labelsize = 7)

# Se eliminan los axes vac铆os
fig.delaxes(axes[2,1])

fig.tight_layout()
plt.subplots_adjust(top=0.9)
fig.suptitle('Diagn贸stico residuos', fontsize = 12, fontweight = "bold");

"""
No se satisfacen las condiciones de normalidad, por lo que los intervalos de confianza estimados para los coeficientes y las predicciones no son fiables.

Los residuos no parecen distribuirse de forma aleatoria en torno a cero, sin mantener aproximadamente la misma variabilidad a lo largo del eje X. Este patr贸n apunta a una falta de homocedasticidad y de distribuci贸n normal.
"""